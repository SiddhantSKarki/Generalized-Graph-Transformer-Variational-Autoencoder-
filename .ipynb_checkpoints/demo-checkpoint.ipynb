{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a307c61-a382-45d6-9520-5697ed1ac185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.utils as utils\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import seaborn as sns\n",
    "import args\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba35429-b904-4e55-835e-74e5ff28475b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "def prepare_gtnvae_data(root, dataset_name='Cora', pos_dim=16):\n",
    "    from torch_geometric.datasets import Planetoid\n",
    "    from torch_geometric.utils import to_dense_adj, train_test_split_edges, get_laplacian\n",
    "\n",
    "    dataset = Planetoid(root=root, name=dataset_name)\n",
    "    data = dataset[0]\n",
    "    data_split = train_test_split_edges(data)\n",
    "    N = data.num_nodes\n",
    "\n",
    "    # Dense node features\n",
    "    x = data.x.unsqueeze(0)\n",
    "\n",
    "    # Dense adjacencies\n",
    "    def to_dense_binary(edge_index):\n",
    "        adj = to_dense_adj(edge_index, max_num_nodes=N)[0]\n",
    "        return (adj > 0).float()\n",
    "\n",
    "    train_adj = to_dense_binary(data_split.train_pos_edge_index).unsqueeze(0)\n",
    "    val_adj   = to_dense_binary(data_split.val_pos_edge_index).unsqueeze(0)\n",
    "    test_adj  = to_dense_binary(data_split.test_pos_edge_index).unsqueeze(0)\n",
    "\n",
    "    # Positional encodings from train edges\n",
    "    edge_index, edge_weight = get_laplacian(data_split.train_pos_edge_index, normalization='sym', num_nodes=N)\n",
    "    L = torch.sparse_coo_tensor(edge_index, edge_weight, (N, N)).to_dense()\n",
    "    eigval, eigvec = torch.linalg.eigh(L)\n",
    "    pos_enc = eigvec[:, 1:pos_dim+1].unsqueeze(0)\n",
    "\n",
    "    return x, pos_enc, train_adj, val_adj, test_adj, data.y\n",
    "\n",
    "x, pos_enc, train_adj, val_adj, test_adj, y = prepare_gtnvae_data(\"../data/\", 'Cora', pos_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8634a77-f40a-4a56-b7c1-80c8b05bc9b1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== DATASET SUMMARY =====\n",
      "Node Feature Shape (x):           torch.Size([1, 2708, 1433])  -> [B, N, d_node_in]\n",
      "Positional Encoding Shape:        torch.Size([1, 2708, 128])  -> [B, N, d_pos]\n",
      "Train Adjacency Shape:            torch.Size([1, 2708, 2708])  -> [B, N, N]\n",
      "Validation Adjacency Shape:       torch.Size([1, 2708, 2708])  -> [B, N, N]\n",
      "Test Adjacency Shape:             torch.Size([1, 2708, 2708])  -> [B, N, N]\n",
      "--------------------------------------\n",
      "Total Nodes (N):                  2708\n",
      "Feature Dimension (d_node_in):    1433\n",
      "Positional Dim (d_pos):           128\n",
      "Total Train Edges:                8976\n",
      "Total Val Edges:                  263\n",
      "Total Test Edges:                 527\n",
      "======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"\\n===== DATASET SUMMARY =====\\n\"\n",
    "    f\"Node Feature Shape (x):           {x.shape}  -> [B, N, d_node_in]\\n\"\n",
    "    f\"Positional Encoding Shape:        {pos_enc.shape}  -> [B, N, d_pos]\\n\"\n",
    "    f\"Train Adjacency Shape:            {train_adj.shape}  -> [B, N, N]\\n\"\n",
    "    f\"Validation Adjacency Shape:       {val_adj.shape}  -> [B, N, N]\\n\"\n",
    "    f\"Test Adjacency Shape:             {test_adj.shape}  -> [B, N, N]\\n\"\n",
    "    f\"--------------------------------------\\n\"\n",
    "    f\"Total Nodes (N):                  {train_adj.size(-1)}\\n\"\n",
    "    f\"Feature Dimension (d_node_in):    {x.size(-1)}\\n\"\n",
    "    f\"Positional Dim (d_pos):           {pos_enc.size(-1)}\\n\"\n",
    "    f\"Total Train Edges:                {int(train_adj.sum().item())}\\n\"\n",
    "    f\"Total Val Edges:                  {int(val_adj.sum().item())}\\n\"\n",
    "    f\"Total Test Edges:                 {int(test_adj.sum().item())}\\n\"\n",
    "    f\"======================================\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eec6cd3-46c5-4f42-b145-43fb30a34b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "device = torch.device(\"mps\")  # or \"cuda\" / \"cpu\"\n",
    "load = None\n",
    "\n",
    "model = GTN_VAE(\n",
    "    input_dim=x.size(-1),\n",
    "    pos_dim=pos_enc.size(-1),\n",
    "    hidden_dim=128,\n",
    "    n_layers=4,\n",
    "    n_heads=4\n",
    ").to(device)\n",
    "\n",
    "if load:\n",
    "    model = torch.load(load, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1d8489f-aabe-43f8-b6b8-7791d48fb0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, pos_enc, train_adj, val_adj, test_adj, y = (\n",
    "    x.to(device),\n",
    "    pos_enc.to(device),\n",
    "    train_adj.to(device),\n",
    "    val_adj.to(device),\n",
    "    test_adj.to(device),\n",
    "    y.to(device)\n",
    ")\n",
    "\n",
    "# Weighting setup\n",
    "pos_weight = float(train_adj.numel() - train_adj.sum()) / train_adj.sum()\n",
    "norm = train_adj.numel() / ((train_adj.numel() - train_adj.sum()) * 2)\n",
    "weight_mask = train_adj.flatten() == 1\n",
    "weight_tensor = torch.ones(weight_mask.size(0), device=device)\n",
    "weight_tensor[weight_mask] = pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0622b8c9-2021-48ec-9a67-08baed3894cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b7e9bef-ffe5-4076-954b-59eb9d1d34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "def compute_metrics(adj_pred, adj_true):\n",
    "    adj_true_np = adj_true.detach().cpu().numpy().flatten()\n",
    "    adj_pred_np = adj_pred.detach().cpu().numpy().flatten()\n",
    "    roc = roc_auc_score(adj_true_np, adj_pred_np)\n",
    "    ap = average_precision_score(adj_true_np, adj_pred_np)\n",
    "    return roc, ap\n",
    "\n",
    "def compute_accuracy(adj_pred, adj_true, threshold=0.5):\n",
    "    pred_bin = (adj_pred > threshold).float()\n",
    "    correct = (pred_bin == adj_true).float().sum()\n",
    "    return (correct / adj_true.numel()).item()\n",
    "\n",
    "def weighted_vae_loss(adj_recon, adj_true, mu, logvar, weight_tensor, norm):\n",
    "    bce = F.binary_cross_entropy(\n",
    "        adj_recon.view(-1),\n",
    "        adj_true.view(-1),\n",
    "        weight=weight_tensor,\n",
    "    )\n",
    "    recon_loss = norm * bce\n",
    "    kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kl_loss, recon_loss, kl_loss\n",
    "\n",
    "def balanced_edge_indices(adj_true, num_samples=5000):\n",
    "    \"\"\"\n",
    "    Returns equal numbers of positive and negative edge indices.\n",
    "    Ensures class balance and guards against small graphs.\n",
    "    \"\"\"\n",
    "    # Flatten and find all positive/negative indices\n",
    "    pos_idx = (adj_true.view(-1) == 1).nonzero(as_tuple=False).view(-1)\n",
    "    neg_idx = (adj_true.view(-1) == 0).nonzero(as_tuple=False).view(-1)\n",
    "\n",
    "    # How many to sample per class\n",
    "    num_pos = min(len(pos_idx), num_samples // 2)\n",
    "    num_neg = num_pos  # strict equality\n",
    "    if num_pos == 0 or num_neg == 0:\n",
    "        raise ValueError(\"No positive or negative edges to sample from.\")\n",
    "\n",
    "    # Random balanced sample\n",
    "    pos_idx = pos_idx[torch.randperm(len(pos_idx))[:num_pos]]\n",
    "    neg_idx = neg_idx[torch.randperm(len(neg_idx))[:num_neg]]\n",
    "    idx = torch.cat([pos_idx, neg_idx])\n",
    "\n",
    "    return idx, num_pos, num_neg\n",
    "\n",
    "\n",
    "def sampled_vae_loss(adj_pred, adj_true, mu, logvar, num_samples=5000):\n",
    "    \"\"\"\n",
    "    Balanced random BCE + KL loss for VGAE-style models.\n",
    "    \"\"\"\n",
    "    idx, num_pos, num_neg = balanced_edge_indices(adj_true, num_samples)\n",
    "    y_true = adj_true.view(-1)[idx]\n",
    "    y_pred = adj_pred.view(-1)[idx]\n",
    "\n",
    "    # BCE over balanced sample\n",
    "    bce = F.binary_cross_entropy(y_pred, y_true)\n",
    "    kl  = -0.001 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return bce + kl, bce, kl\n",
    "\n",
    "\n",
    "def sampled_metrics(adj_pred, adj_true, num_samples=5000):\n",
    "    \"\"\"\n",
    "    Computes ROC-AUC, AP, and Accuracy on balanced edge samples.\n",
    "    \"\"\"\n",
    "    idx, num_pos, num_neg = balanced_edge_indices(adj_true, num_samples)\n",
    "    y_true = adj_true.view(-1)[idx].cpu().numpy()\n",
    "    y_pred = adj_pred.view(-1)[idx].detach().cpu().numpy()\n",
    "\n",
    "    roc = roc_auc_score(y_true, y_pred)\n",
    "    ap  = average_precision_score(y_true, y_pred)\n",
    "    acc = ((torch.tensor(y_pred) > 0.5).float().numpy() == y_true).mean()\n",
    "    return roc, ap, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "130b67c7-ee07-4110-8db7-0b1da23f1789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_in_out(model_comp, inputs):\n",
    "    output = model_comp(*inputs)\n",
    "    output_mean = output.mean()\n",
    "    output_std = output.std()\n",
    "    print(f\"output: {output}\\noutput_mean:{output_mean}\\noutput_std:{output_std}\")\n",
    "    return output\n",
    "\n",
    "def model_debug_auto(model_comp, inputs, verbose=True):\n",
    "    # Run forward pass\n",
    "    if not isinstance(inputs, (tuple, list)):\n",
    "        inputs = (inputs,)\n",
    "    \n",
    "    output = model_comp(*inputs)\n",
    "    \n",
    "    def summarize_tensor(name, tensor):\n",
    "        if isinstance(tensor, torch.Tensor):\n",
    "            return {\n",
    "                \"name\": name,\n",
    "                \"shape\": tuple(tensor.shape),\n",
    "                \"dtype\": tensor.dtype,\n",
    "                \"min\": tensor.min().item(),\n",
    "                \"max\": tensor.max().item(),\n",
    "                \"mean\": tensor.mean().item(),\n",
    "                \"std\": tensor.std().item()\n",
    "            }\n",
    "        elif isinstance(tensor, (list, tuple)):\n",
    "            return [summarize_tensor(f\"{name}[{i}]\", t) for i, t in enumerate(tensor)]\n",
    "        elif isinstance(tensor, dict):\n",
    "            return {k: summarize_tensor(f\"{name}.{k}\", v) for k, v in tensor.items()}\n",
    "        else:\n",
    "            return {name: str(type(tensor))}\n",
    "\n",
    "    # Summarize input(s) and output(s)\n",
    "    input_summary = [summarize_tensor(f\"input[{i}]\", inp) for i, inp in enumerate(inputs)]\n",
    "    output_summary = summarize_tensor(\"output\", output)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"=== INPUT SUMMARY ===\")\n",
    "        for s in input_summary:\n",
    "            print(s)\n",
    "        print(\"\\n=== OUTPUT SUMMARY ===\")\n",
    "        print(output_summary)\n",
    "    \n",
    "    return output, input_summary, output_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cee27f95-ecb8-42a9-b5a0-6587b8a3f327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: tensor([[[ 0.0461,  0.1544, -0.1309,  ...,  0.0707,  0.1225,  0.1730],\n",
      "         [ 0.1151,  0.1375, -0.0638,  ...,  0.0877, -0.0735,  0.1419],\n",
      "         [-0.0054,  0.2004, -0.1103,  ..., -0.0064,  0.0354,  0.0816],\n",
      "         ...,\n",
      "         [-0.0194,  0.1396, -0.0790,  ...,  0.0483,  0.2426,  0.0196],\n",
      "         [ 0.1832,  0.1057, -0.1759,  ...,  0.1101,  0.0213,  0.0548],\n",
      "         [ 0.1285,  0.1260, -0.1853,  ...,  0.0057,  0.1105,  0.0630]]],\n",
      "       device='mps:0', grad_fn=<AddBackward0>)\n",
      "output_mean:0.011874960735440254\n",
      "output_std:0.11318128556013107\n"
     ]
    }
   ],
   "source": [
    "t_input = model_in_out(model.transformer_encoder.embed, (x, pos_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7ea219c-ebdb-4d91-88c9-ec08f0e871db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adj_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m adj_full \u001b[38;5;241m=\u001b[39m \u001b[43madj_full\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      2\u001b[0m model_debug_auto(model\u001b[38;5;241m.\u001b[39mtransformer_encoder, (x, pos_enc, adj_full))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adj_full' is not defined"
     ]
    }
   ],
   "source": [
    "adj_full = adj_full.to(device)\n",
    "model_debug_auto(model.transformer_encoder, (x, pos_enc, adj_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e7297a3-b166-4084-8844-efba6b055ebb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adj_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m A_pred \u001b[38;5;241m=\u001b[39m model(x, pos_enc, \u001b[43madj_full\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adj_full' is not defined"
     ]
    }
   ],
   "source": [
    "A_pred = model(x, pos_enc, adj_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d2e5919-f291-4e43-a420-e574dcfac563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(train_adj[0, :, :].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6eb73d6-c5f3-46d4-a8d7-06e3e1c1dc78",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_adj_pred \u001b[38;5;241m=\u001b[39m get_adj(\u001b[43mtrain_mask\u001b[49m, A_pred)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_mask' is not defined"
     ]
    }
   ],
   "source": [
    "train_adj_pred = get_adj(train_mask, A_pred).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "445d8334-c48d-4821-80fa-23a3f8dd1d45",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(\u001b[43mA_pred\u001b[49m[\u001b[38;5;241m0\u001b[39m, :, :])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'A_pred' is not defined"
     ]
    }
   ],
   "source": [
    "sns.heatmap(A_pred[0, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4902d4e4-e5fd-4d91-bc3b-1147d3578ab1",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c2a1d19-6a9a-4855-849b-8e4ba92ee8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [001/200] | Train Loss: 4.7473 | Val Loss: 4.5702 | Train Acc: 0.5032 | Val Acc: 0.4950 | Train ROC: 0.5038 | Val ROC: 0.5086 | Train AP: 0.5019 | Val AP: 0.5080\n",
      "Epoch [002/200] | Train Loss: 4.2339 | Val Loss: 3.9358 | Train Acc: 0.5180 | Val Acc: 0.4975 | Train ROC: 0.5258 | Val ROC: 0.5035 | Train AP: 0.5148 | Val AP: 0.5013\n",
      "Epoch [003/200] | Train Loss: 3.8169 | Val Loss: 3.7201 | Train Acc: 0.5201 | Val Acc: 0.5600 | Train ROC: 0.5242 | Val ROC: 0.5543 | Train AP: 0.5154 | Val AP: 0.5398\n",
      "Epoch [004/200] | Train Loss: 3.8571 | Val Loss: 3.8252 | Train Acc: 0.5051 | Val Acc: 0.5075 | Train ROC: 0.5136 | Val ROC: 0.4986 | Train AP: 0.5097 | Val AP: 0.4936\n",
      "Epoch [005/200] | Train Loss: 3.8008 | Val Loss: 3.2760 | Train Acc: 0.5224 | Val Acc: 0.5150 | Train ROC: 0.5229 | Val ROC: 0.5214 | Train AP: 0.5139 | Val AP: 0.5096\n",
      "Epoch [006/200] | Train Loss: 3.6599 | Val Loss: 3.3327 | Train Acc: 0.5200 | Val Acc: 0.5275 | Train ROC: 0.5248 | Val ROC: 0.5325 | Train AP: 0.5153 | Val AP: 0.5170\n",
      "Epoch [007/200] | Train Loss: 3.5054 | Val Loss: 3.3646 | Train Acc: 0.5250 | Val Acc: 0.5650 | Train ROC: 0.5369 | Val ROC: 0.5691 | Train AP: 0.5258 | Val AP: 0.5489\n",
      "Epoch [008/200] | Train Loss: 3.4249 | Val Loss: 2.6679 | Train Acc: 0.5238 | Val Acc: 0.5850 | Train ROC: 0.5366 | Val ROC: 0.6231 | Train AP: 0.5276 | Val AP: 0.5989\n",
      "Epoch [009/200] | Train Loss: 3.2076 | Val Loss: 3.0307 | Train Acc: 0.5231 | Val Acc: 0.5050 | Train ROC: 0.5333 | Val ROC: 0.5179 | Train AP: 0.5237 | Val AP: 0.5134\n",
      "Epoch [010/200] | Train Loss: 3.1123 | Val Loss: 2.9579 | Train Acc: 0.5375 | Val Acc: 0.5100 | Train ROC: 0.5517 | Val ROC: 0.5313 | Train AP: 0.5417 | Val AP: 0.5330\n",
      "Epoch [011/200] | Train Loss: 3.0106 | Val Loss: 2.9048 | Train Acc: 0.5479 | Val Acc: 0.5400 | Train ROC: 0.5712 | Val ROC: 0.5689 | Train AP: 0.5547 | Val AP: 0.5622\n",
      "Epoch [012/200] | Train Loss: 2.7549 | Val Loss: 2.4975 | Train Acc: 0.5654 | Val Acc: 0.6100 | Train ROC: 0.5989 | Val ROC: 0.6288 | Train AP: 0.5780 | Val AP: 0.5860\n",
      "Epoch [013/200] | Train Loss: 2.6854 | Val Loss: 2.7089 | Train Acc: 0.5656 | Val Acc: 0.5575 | Train ROC: 0.5984 | Val ROC: 0.5936 | Train AP: 0.5782 | Val AP: 0.5871\n",
      "Epoch [014/200] | Train Loss: 2.4038 | Val Loss: 2.3044 | Train Acc: 0.5816 | Val Acc: 0.6200 | Train ROC: 0.6206 | Val ROC: 0.6520 | Train AP: 0.6012 | Val AP: 0.6164\n",
      "Epoch [015/200] | Train Loss: 2.2148 | Val Loss: 2.3091 | Train Acc: 0.6074 | Val Acc: 0.6000 | Train ROC: 0.6619 | Val ROC: 0.6424 | Train AP: 0.6342 | Val AP: 0.6232\n",
      "Epoch [016/200] | Train Loss: 2.1184 | Val Loss: 1.8625 | Train Acc: 0.6118 | Val Acc: 0.6025 | Train ROC: 0.6691 | Val ROC: 0.6370 | Train AP: 0.6467 | Val AP: 0.6092\n",
      "Epoch [017/200] | Train Loss: 2.0041 | Val Loss: 1.7544 | Train Acc: 0.6049 | Val Acc: 0.5650 | Train ROC: 0.6679 | Val ROC: 0.6627 | Train AP: 0.6449 | Val AP: 0.6864\n",
      "Epoch [018/200] | Train Loss: 1.9074 | Val Loss: 1.6562 | Train Acc: 0.6226 | Val Acc: 0.6050 | Train ROC: 0.7014 | Val ROC: 0.6578 | Train AP: 0.6857 | Val AP: 0.6358\n",
      "Epoch [019/200] | Train Loss: 1.7303 | Val Loss: 1.6524 | Train Acc: 0.6325 | Val Acc: 0.6375 | Train ROC: 0.7028 | Val ROC: 0.6988 | Train AP: 0.6825 | Val AP: 0.6994\n",
      "Epoch [020/200] | Train Loss: 1.5853 | Val Loss: 1.4054 | Train Acc: 0.6204 | Val Acc: 0.6125 | Train ROC: 0.6891 | Val ROC: 0.6668 | Train AP: 0.6753 | Val AP: 0.6624\n",
      "Epoch [021/200] | Train Loss: 1.4474 | Val Loss: 1.3712 | Train Acc: 0.6195 | Val Acc: 0.5975 | Train ROC: 0.6851 | Val ROC: 0.6646 | Train AP: 0.6727 | Val AP: 0.6740\n",
      "Epoch [022/200] | Train Loss: 1.2848 | Val Loss: 1.2050 | Train Acc: 0.6105 | Val Acc: 0.6000 | Train ROC: 0.6790 | Val ROC: 0.6511 | Train AP: 0.6700 | Val AP: 0.6388\n",
      "Epoch [023/200] | Train Loss: 1.1980 | Val Loss: 1.2242 | Train Acc: 0.6111 | Val Acc: 0.6125 | Train ROC: 0.6732 | Val ROC: 0.6881 | Train AP: 0.6665 | Val AP: 0.6832\n",
      "Epoch [024/200] | Train Loss: 1.1443 | Val Loss: 1.0233 | Train Acc: 0.5910 | Val Acc: 0.6100 | Train ROC: 0.6501 | Val ROC: 0.6746 | Train AP: 0.6512 | Val AP: 0.6734\n",
      "Epoch [025/200] | Train Loss: 1.0549 | Val Loss: 1.0347 | Train Acc: 0.6081 | Val Acc: 0.5875 | Train ROC: 0.6729 | Val ROC: 0.6379 | Train AP: 0.6729 | Val AP: 0.6319\n",
      "Epoch [026/200] | Train Loss: 0.9516 | Val Loss: 0.8881 | Train Acc: 0.5954 | Val Acc: 0.5775 | Train ROC: 0.6602 | Val ROC: 0.6202 | Train AP: 0.6566 | Val AP: 0.6215\n",
      "Epoch [027/200] | Train Loss: 0.9034 | Val Loss: 0.8101 | Train Acc: 0.6008 | Val Acc: 0.5975 | Train ROC: 0.6596 | Val ROC: 0.6526 | Train AP: 0.6598 | Val AP: 0.6616\n",
      "Epoch [028/200] | Train Loss: 0.8543 | Val Loss: 0.9014 | Train Acc: 0.6075 | Val Acc: 0.5725 | Train ROC: 0.6686 | Val ROC: 0.6353 | Train AP: 0.6592 | Val AP: 0.6588\n",
      "Epoch [029/200] | Train Loss: 0.8098 | Val Loss: 0.8435 | Train Acc: 0.6124 | Val Acc: 0.5950 | Train ROC: 0.6836 | Val ROC: 0.6321 | Train AP: 0.6834 | Val AP: 0.6105\n",
      "Epoch [030/200] | Train Loss: 0.8008 | Val Loss: 0.8708 | Train Acc: 0.6118 | Val Acc: 0.5750 | Train ROC: 0.6761 | Val ROC: 0.6407 | Train AP: 0.6686 | Val AP: 0.6618\n",
      "Epoch [031/200] | Train Loss: 0.7640 | Val Loss: 0.7280 | Train Acc: 0.6175 | Val Acc: 0.5975 | Train ROC: 0.6879 | Val ROC: 0.6796 | Train AP: 0.6845 | Val AP: 0.6611\n",
      "Epoch [032/200] | Train Loss: 0.7209 | Val Loss: 0.7275 | Train Acc: 0.6336 | Val Acc: 0.6075 | Train ROC: 0.7095 | Val ROC: 0.6746 | Train AP: 0.7123 | Val AP: 0.6551\n",
      "Epoch [033/200] | Train Loss: 0.6953 | Val Loss: 0.6951 | Train Acc: 0.6450 | Val Acc: 0.6675 | Train ROC: 0.7310 | Val ROC: 0.7291 | Train AP: 0.7239 | Val AP: 0.6996\n",
      "Epoch [034/200] | Train Loss: 0.6844 | Val Loss: 0.6632 | Train Acc: 0.6518 | Val Acc: 0.6300 | Train ROC: 0.7472 | Val ROC: 0.7050 | Train AP: 0.7440 | Val AP: 0.7105\n",
      "Epoch [035/200] | Train Loss: 0.6606 | Val Loss: 0.6757 | Train Acc: 0.6597 | Val Acc: 0.6650 | Train ROC: 0.7642 | Val ROC: 0.7637 | Train AP: 0.7603 | Val AP: 0.7603\n",
      "Epoch [036/200] | Train Loss: 0.6495 | Val Loss: 0.6442 | Train Acc: 0.6756 | Val Acc: 0.7125 | Train ROC: 0.7865 | Val ROC: 0.7824 | Train AP: 0.7843 | Val AP: 0.7576\n",
      "Epoch [037/200] | Train Loss: 0.6148 | Val Loss: 0.6241 | Train Acc: 0.6850 | Val Acc: 0.6950 | Train ROC: 0.8064 | Val ROC: 0.7846 | Train AP: 0.8056 | Val AP: 0.7729\n",
      "Epoch [038/200] | Train Loss: 0.6147 | Val Loss: 0.6012 | Train Acc: 0.6847 | Val Acc: 0.6775 | Train ROC: 0.8095 | Val ROC: 0.7910 | Train AP: 0.8056 | Val AP: 0.7733\n",
      "Epoch [039/200] | Train Loss: 0.6076 | Val Loss: 0.6166 | Train Acc: 0.7061 | Val Acc: 0.6625 | Train ROC: 0.8337 | Val ROC: 0.7990 | Train AP: 0.8248 | Val AP: 0.8028\n",
      "Epoch [040/200] | Train Loss: 0.5807 | Val Loss: 0.6995 | Train Acc: 0.7091 | Val Acc: 0.6550 | Train ROC: 0.8425 | Val ROC: 0.7713 | Train AP: 0.8366 | Val AP: 0.7657\n",
      "Epoch [041/200] | Train Loss: 0.5896 | Val Loss: 0.6300 | Train Acc: 0.7060 | Val Acc: 0.6675 | Train ROC: 0.8468 | Val ROC: 0.7812 | Train AP: 0.8401 | Val AP: 0.7864\n",
      "Epoch [042/200] | Train Loss: 0.5812 | Val Loss: 0.6056 | Train Acc: 0.7074 | Val Acc: 0.7100 | Train ROC: 0.8399 | Val ROC: 0.8135 | Train AP: 0.8351 | Val AP: 0.8111\n",
      "Epoch [043/200] | Train Loss: 0.5784 | Val Loss: 0.5745 | Train Acc: 0.7120 | Val Acc: 0.7050 | Train ROC: 0.8555 | Val ROC: 0.8221 | Train AP: 0.8534 | Val AP: 0.8221\n",
      "Epoch [044/200] | Train Loss: 0.5758 | Val Loss: 0.6569 | Train Acc: 0.7113 | Val Acc: 0.6625 | Train ROC: 0.8590 | Val ROC: 0.7999 | Train AP: 0.8593 | Val AP: 0.7999\n",
      "Epoch [045/200] | Train Loss: 0.5531 | Val Loss: 0.6239 | Train Acc: 0.7145 | Val Acc: 0.6925 | Train ROC: 0.8687 | Val ROC: 0.8189 | Train AP: 0.8646 | Val AP: 0.8031\n",
      "Epoch [046/200] | Train Loss: 0.5534 | Val Loss: 0.5861 | Train Acc: 0.7110 | Val Acc: 0.7200 | Train ROC: 0.8636 | Val ROC: 0.8331 | Train AP: 0.8623 | Val AP: 0.8315\n",
      "Epoch [047/200] | Train Loss: 0.5486 | Val Loss: 0.5734 | Train Acc: 0.7179 | Val Acc: 0.7275 | Train ROC: 0.8677 | Val ROC: 0.8220 | Train AP: 0.8679 | Val AP: 0.7973\n",
      "Epoch [048/200] | Train Loss: 0.5472 | Val Loss: 0.5413 | Train Acc: 0.7151 | Val Acc: 0.7325 | Train ROC: 0.8689 | Val ROC: 0.8527 | Train AP: 0.8633 | Val AP: 0.8380\n",
      "Epoch [049/200] | Train Loss: 0.5407 | Val Loss: 0.5544 | Train Acc: 0.7124 | Val Acc: 0.6750 | Train ROC: 0.8621 | Val ROC: 0.8190 | Train AP: 0.8610 | Val AP: 0.8074\n",
      "Epoch [050/200] | Train Loss: 0.5461 | Val Loss: 0.5574 | Train Acc: 0.7221 | Val Acc: 0.7075 | Train ROC: 0.8764 | Val ROC: 0.8340 | Train AP: 0.8725 | Val AP: 0.8370\n",
      "Epoch [051/200] | Train Loss: 0.5337 | Val Loss: 0.5253 | Train Acc: 0.7216 | Val Acc: 0.7150 | Train ROC: 0.8768 | Val ROC: 0.8259 | Train AP: 0.8724 | Val AP: 0.8077\n",
      "Epoch [052/200] | Train Loss: 0.5297 | Val Loss: 0.5498 | Train Acc: 0.7320 | Val Acc: 0.7250 | Train ROC: 0.8877 | Val ROC: 0.8464 | Train AP: 0.8831 | Val AP: 0.8418\n",
      "Epoch [053/200] | Train Loss: 0.5272 | Val Loss: 0.5329 | Train Acc: 0.7299 | Val Acc: 0.7175 | Train ROC: 0.8873 | Val ROC: 0.8497 | Train AP: 0.8814 | Val AP: 0.8239\n",
      "Epoch [054/200] | Train Loss: 0.5180 | Val Loss: 0.5579 | Train Acc: 0.7301 | Val Acc: 0.7225 | Train ROC: 0.8907 | Val ROC: 0.8709 | Train AP: 0.8825 | Val AP: 0.8629\n",
      "Epoch [055/200] | Train Loss: 0.5217 | Val Loss: 0.5393 | Train Acc: 0.7265 | Val Acc: 0.6950 | Train ROC: 0.8924 | Val ROC: 0.8467 | Train AP: 0.8885 | Val AP: 0.8467\n",
      "Epoch [056/200] | Train Loss: 0.5204 | Val Loss: 0.5435 | Train Acc: 0.7291 | Val Acc: 0.7325 | Train ROC: 0.8969 | Val ROC: 0.8489 | Train AP: 0.8922 | Val AP: 0.8408\n",
      "Epoch [057/200] | Train Loss: 0.5161 | Val Loss: 0.5388 | Train Acc: 0.7310 | Val Acc: 0.7275 | Train ROC: 0.8966 | Val ROC: 0.8613 | Train AP: 0.8922 | Val AP: 0.8689\n",
      "Epoch [058/200] | Train Loss: 0.5245 | Val Loss: 0.5691 | Train Acc: 0.7405 | Val Acc: 0.6800 | Train ROC: 0.9046 | Val ROC: 0.8418 | Train AP: 0.9013 | Val AP: 0.8468\n",
      "Epoch [059/200] | Train Loss: 0.5031 | Val Loss: 0.5521 | Train Acc: 0.7399 | Val Acc: 0.7100 | Train ROC: 0.9106 | Val ROC: 0.8448 | Train AP: 0.9070 | Val AP: 0.8495\n",
      "Epoch [060/200] | Train Loss: 0.5127 | Val Loss: 0.5270 | Train Acc: 0.7371 | Val Acc: 0.6950 | Train ROC: 0.9120 | Val ROC: 0.8503 | Train AP: 0.9095 | Val AP: 0.8482\n",
      "Epoch [061/200] | Train Loss: 0.5131 | Val Loss: 0.5518 | Train Acc: 0.7350 | Val Acc: 0.7100 | Train ROC: 0.9091 | Val ROC: 0.8441 | Train AP: 0.9055 | Val AP: 0.8410\n",
      "Epoch [062/200] | Train Loss: 0.5064 | Val Loss: 0.5525 | Train Acc: 0.7494 | Val Acc: 0.7000 | Train ROC: 0.9200 | Val ROC: 0.8449 | Train AP: 0.9179 | Val AP: 0.8577\n",
      "Epoch [063/200] | Train Loss: 0.5000 | Val Loss: 0.5346 | Train Acc: 0.7440 | Val Acc: 0.7350 | Train ROC: 0.9131 | Val ROC: 0.8687 | Train AP: 0.9089 | Val AP: 0.8685\n",
      "Epoch [064/200] | Train Loss: 0.5146 | Val Loss: 0.5355 | Train Acc: 0.7395 | Val Acc: 0.7550 | Train ROC: 0.9160 | Val ROC: 0.9029 | Train AP: 0.9125 | Val AP: 0.9001\n",
      "Epoch [065/200] | Train Loss: 0.5091 | Val Loss: 0.5034 | Train Acc: 0.7450 | Val Acc: 0.7225 | Train ROC: 0.9223 | Val ROC: 0.8605 | Train AP: 0.9188 | Val AP: 0.8702\n",
      "Epoch [066/200] | Train Loss: 0.4992 | Val Loss: 0.5410 | Train Acc: 0.7398 | Val Acc: 0.7100 | Train ROC: 0.9136 | Val ROC: 0.8792 | Train AP: 0.9102 | Val AP: 0.8805\n",
      "Epoch [067/200] | Train Loss: 0.5031 | Val Loss: 0.5904 | Train Acc: 0.7478 | Val Acc: 0.7125 | Train ROC: 0.9250 | Val ROC: 0.8676 | Train AP: 0.9223 | Val AP: 0.8681\n",
      "Epoch [068/200] | Train Loss: 0.4933 | Val Loss: 0.5149 | Train Acc: 0.7401 | Val Acc: 0.7325 | Train ROC: 0.9243 | Val ROC: 0.8607 | Train AP: 0.9195 | Val AP: 0.8616\n",
      "Epoch [069/200] | Train Loss: 0.4952 | Val Loss: 0.5214 | Train Acc: 0.7401 | Val Acc: 0.7375 | Train ROC: 0.9265 | Val ROC: 0.8696 | Train AP: 0.9240 | Val AP: 0.8674\n",
      "Epoch [070/200] | Train Loss: 0.5024 | Val Loss: 0.5386 | Train Acc: 0.7508 | Val Acc: 0.7500 | Train ROC: 0.9169 | Val ROC: 0.9055 | Train AP: 0.9083 | Val AP: 0.9080\n",
      "Epoch [071/200] | Train Loss: 0.4900 | Val Loss: 0.5526 | Train Acc: 0.7474 | Val Acc: 0.7275 | Train ROC: 0.9240 | Val ROC: 0.8739 | Train AP: 0.9189 | Val AP: 0.8745\n",
      "Epoch [072/200] | Train Loss: 0.4924 | Val Loss: 0.5469 | Train Acc: 0.7489 | Val Acc: 0.7100 | Train ROC: 0.9341 | Val ROC: 0.8808 | Train AP: 0.9324 | Val AP: 0.8836\n",
      "Epoch [073/200] | Train Loss: 0.4909 | Val Loss: 0.5135 | Train Acc: 0.7534 | Val Acc: 0.7350 | Train ROC: 0.9314 | Val ROC: 0.8684 | Train AP: 0.9271 | Val AP: 0.8729\n",
      "Epoch [074/200] | Train Loss: 0.4961 | Val Loss: 0.5592 | Train Acc: 0.7465 | Val Acc: 0.7400 | Train ROC: 0.9320 | Val ROC: 0.8722 | Train AP: 0.9292 | Val AP: 0.8671\n",
      "Epoch [075/200] | Train Loss: 0.4844 | Val Loss: 0.5023 | Train Acc: 0.7462 | Val Acc: 0.7175 | Train ROC: 0.9302 | Val ROC: 0.8661 | Train AP: 0.9260 | Val AP: 0.8662\n",
      "Epoch [076/200] | Train Loss: 0.4803 | Val Loss: 0.5281 | Train Acc: 0.7516 | Val Acc: 0.7550 | Train ROC: 0.9371 | Val ROC: 0.9093 | Train AP: 0.9327 | Val AP: 0.9155\n",
      "Epoch [077/200] | Train Loss: 0.4832 | Val Loss: 0.5060 | Train Acc: 0.7496 | Val Acc: 0.7650 | Train ROC: 0.9394 | Val ROC: 0.9161 | Train AP: 0.9342 | Val AP: 0.9175\n",
      "Epoch [078/200] | Train Loss: 0.4799 | Val Loss: 0.5315 | Train Acc: 0.7538 | Val Acc: 0.7100 | Train ROC: 0.9358 | Val ROC: 0.8675 | Train AP: 0.9314 | Val AP: 0.8688\n",
      "Epoch [079/200] | Train Loss: 0.4862 | Val Loss: 0.4889 | Train Acc: 0.7549 | Val Acc: 0.7025 | Train ROC: 0.9428 | Val ROC: 0.8788 | Train AP: 0.9388 | Val AP: 0.8585\n",
      "Epoch [080/200] | Train Loss: 0.4965 | Val Loss: 0.5384 | Train Acc: 0.7530 | Val Acc: 0.7000 | Train ROC: 0.9388 | Val ROC: 0.8758 | Train AP: 0.9346 | Val AP: 0.8832\n",
      "Epoch [081/200] | Train Loss: 0.4882 | Val Loss: 0.5029 | Train Acc: 0.7565 | Val Acc: 0.7375 | Train ROC: 0.9421 | Val ROC: 0.8950 | Train AP: 0.9386 | Val AP: 0.8938\n",
      "Epoch [082/200] | Train Loss: 0.4805 | Val Loss: 0.4852 | Train Acc: 0.7469 | Val Acc: 0.7550 | Train ROC: 0.9449 | Val ROC: 0.8960 | Train AP: 0.9397 | Val AP: 0.8904\n",
      "Epoch [083/200] | Train Loss: 0.4867 | Val Loss: 0.5160 | Train Acc: 0.7561 | Val Acc: 0.7175 | Train ROC: 0.9492 | Val ROC: 0.8793 | Train AP: 0.9455 | Val AP: 0.8874\n",
      "Epoch [084/200] | Train Loss: 0.4854 | Val Loss: 0.5236 | Train Acc: 0.7475 | Val Acc: 0.7625 | Train ROC: 0.9434 | Val ROC: 0.8874 | Train AP: 0.9398 | Val AP: 0.8712\n",
      "Epoch [085/200] | Train Loss: 0.4831 | Val Loss: 0.5087 | Train Acc: 0.7465 | Val Acc: 0.7225 | Train ROC: 0.9447 | Val ROC: 0.8774 | Train AP: 0.9418 | Val AP: 0.8740\n",
      "Epoch [086/200] | Train Loss: 0.4809 | Val Loss: 0.5170 | Train Acc: 0.7456 | Val Acc: 0.7550 | Train ROC: 0.9493 | Val ROC: 0.8986 | Train AP: 0.9464 | Val AP: 0.8810\n",
      "Epoch [087/200] | Train Loss: 0.4772 | Val Loss: 0.5048 | Train Acc: 0.7448 | Val Acc: 0.7425 | Train ROC: 0.9441 | Val ROC: 0.8901 | Train AP: 0.9408 | Val AP: 0.8905\n",
      "Epoch [088/200] | Train Loss: 0.4839 | Val Loss: 0.4832 | Train Acc: 0.7469 | Val Acc: 0.7150 | Train ROC: 0.9449 | Val ROC: 0.8877 | Train AP: 0.9409 | Val AP: 0.8920\n",
      "Epoch [089/200] | Train Loss: 0.4819 | Val Loss: 0.5038 | Train Acc: 0.7456 | Val Acc: 0.7250 | Train ROC: 0.9452 | Val ROC: 0.8752 | Train AP: 0.9408 | Val AP: 0.8721\n",
      "Epoch [090/200] | Train Loss: 0.4751 | Val Loss: 0.5176 | Train Acc: 0.7488 | Val Acc: 0.7425 | Train ROC: 0.9528 | Val ROC: 0.9006 | Train AP: 0.9497 | Val AP: 0.8953\n",
      "Epoch [091/200] | Train Loss: 0.4750 | Val Loss: 0.5179 | Train Acc: 0.7505 | Val Acc: 0.7375 | Train ROC: 0.9483 | Val ROC: 0.8946 | Train AP: 0.9456 | Val AP: 0.9033\n",
      "Epoch [092/200] | Train Loss: 0.4656 | Val Loss: 0.5545 | Train Acc: 0.7549 | Val Acc: 0.7325 | Train ROC: 0.9531 | Val ROC: 0.8775 | Train AP: 0.9475 | Val AP: 0.8706\n",
      "Epoch [093/200] | Train Loss: 0.4715 | Val Loss: 0.5256 | Train Acc: 0.7496 | Val Acc: 0.7575 | Train ROC: 0.9538 | Val ROC: 0.9037 | Train AP: 0.9493 | Val AP: 0.9049\n",
      "Epoch [094/200] | Train Loss: 0.4757 | Val Loss: 0.5099 | Train Acc: 0.7480 | Val Acc: 0.7650 | Train ROC: 0.9516 | Val ROC: 0.9023 | Train AP: 0.9464 | Val AP: 0.8864\n",
      "Epoch [095/200] | Train Loss: 0.4684 | Val Loss: 0.5165 | Train Acc: 0.7445 | Val Acc: 0.7875 | Train ROC: 0.9518 | Val ROC: 0.9052 | Train AP: 0.9470 | Val AP: 0.9053\n",
      "Epoch [096/200] | Train Loss: 0.4735 | Val Loss: 0.5060 | Train Acc: 0.7549 | Val Acc: 0.7125 | Train ROC: 0.9555 | Val ROC: 0.8768 | Train AP: 0.9509 | Val AP: 0.8718\n",
      "Epoch [097/200] | Train Loss: 0.4678 | Val Loss: 0.5208 | Train Acc: 0.7569 | Val Acc: 0.7700 | Train ROC: 0.9574 | Val ROC: 0.9325 | Train AP: 0.9520 | Val AP: 0.9262\n",
      "Epoch [098/200] | Train Loss: 0.4635 | Val Loss: 0.4712 | Train Acc: 0.7560 | Val Acc: 0.7375 | Train ROC: 0.9573 | Val ROC: 0.9160 | Train AP: 0.9524 | Val AP: 0.9178\n",
      "Epoch [099/200] | Train Loss: 0.4722 | Val Loss: 0.4952 | Train Acc: 0.7526 | Val Acc: 0.7500 | Train ROC: 0.9573 | Val ROC: 0.9018 | Train AP: 0.9539 | Val AP: 0.9030\n",
      "Epoch [100/200] | Train Loss: 0.4664 | Val Loss: 0.4624 | Train Acc: 0.7530 | Val Acc: 0.7200 | Train ROC: 0.9557 | Val ROC: 0.9014 | Train AP: 0.9504 | Val AP: 0.9050\n",
      "Epoch [101/200] | Train Loss: 0.4595 | Val Loss: 0.5051 | Train Acc: 0.7545 | Val Acc: 0.7575 | Train ROC: 0.9585 | Val ROC: 0.9078 | Train AP: 0.9546 | Val AP: 0.9059\n",
      "Epoch [102/200] | Train Loss: 0.4641 | Val Loss: 0.5337 | Train Acc: 0.7548 | Val Acc: 0.7425 | Train ROC: 0.9613 | Val ROC: 0.9134 | Train AP: 0.9578 | Val AP: 0.9200\n",
      "Epoch [103/200] | Train Loss: 0.4688 | Val Loss: 0.5367 | Train Acc: 0.7519 | Val Acc: 0.7400 | Train ROC: 0.9602 | Val ROC: 0.8806 | Train AP: 0.9561 | Val AP: 0.8627\n",
      "Epoch [104/200] | Train Loss: 0.4664 | Val Loss: 0.4970 | Train Acc: 0.7565 | Val Acc: 0.7325 | Train ROC: 0.9643 | Val ROC: 0.9085 | Train AP: 0.9610 | Val AP: 0.9046\n",
      "Epoch [105/200] | Train Loss: 0.4614 | Val Loss: 0.5159 | Train Acc: 0.7555 | Val Acc: 0.7500 | Train ROC: 0.9616 | Val ROC: 0.9043 | Train AP: 0.9578 | Val AP: 0.9038\n",
      "Epoch [106/200] | Train Loss: 0.4678 | Val Loss: 0.5309 | Train Acc: 0.7481 | Val Acc: 0.7550 | Train ROC: 0.9629 | Val ROC: 0.9133 | Train AP: 0.9600 | Val AP: 0.9115\n",
      "Epoch [107/200] | Train Loss: 0.4551 | Val Loss: 0.4893 | Train Acc: 0.7605 | Val Acc: 0.7550 | Train ROC: 0.9637 | Val ROC: 0.9165 | Train AP: 0.9584 | Val AP: 0.9244\n",
      "Epoch [108/200] | Train Loss: 0.4671 | Val Loss: 0.4927 | Train Acc: 0.7606 | Val Acc: 0.7275 | Train ROC: 0.9654 | Val ROC: 0.8991 | Train AP: 0.9616 | Val AP: 0.8935\n",
      "Epoch [109/200] | Train Loss: 0.4613 | Val Loss: 0.4839 | Train Acc: 0.7550 | Val Acc: 0.7325 | Train ROC: 0.9663 | Val ROC: 0.9050 | Train AP: 0.9630 | Val AP: 0.8986\n",
      "Epoch [110/200] | Train Loss: 0.4713 | Val Loss: 0.5281 | Train Acc: 0.7494 | Val Acc: 0.7400 | Train ROC: 0.9634 | Val ROC: 0.8977 | Train AP: 0.9583 | Val AP: 0.8967\n",
      "Epoch [111/200] | Train Loss: 0.4610 | Val Loss: 0.5036 | Train Acc: 0.7536 | Val Acc: 0.7425 | Train ROC: 0.9644 | Val ROC: 0.9194 | Train AP: 0.9598 | Val AP: 0.9099\n",
      "Epoch [112/200] | Train Loss: 0.4679 | Val Loss: 0.5052 | Train Acc: 0.7416 | Val Acc: 0.7300 | Train ROC: 0.9647 | Val ROC: 0.9098 | Train AP: 0.9629 | Val AP: 0.9161\n",
      "Epoch [113/200] | Train Loss: 0.4651 | Val Loss: 0.5174 | Train Acc: 0.7601 | Val Acc: 0.7200 | Train ROC: 0.9688 | Val ROC: 0.8940 | Train AP: 0.9662 | Val AP: 0.8938\n",
      "Epoch [114/200] | Train Loss: 0.4565 | Val Loss: 0.4713 | Train Acc: 0.7556 | Val Acc: 0.7225 | Train ROC: 0.9651 | Val ROC: 0.9065 | Train AP: 0.9600 | Val AP: 0.9151\n",
      "Epoch [115/200] | Train Loss: 0.4680 | Val Loss: 0.4731 | Train Acc: 0.7524 | Val Acc: 0.7325 | Train ROC: 0.9692 | Val ROC: 0.9237 | Train AP: 0.9645 | Val AP: 0.9286\n",
      "Epoch [116/200] | Train Loss: 0.4584 | Val Loss: 0.5325 | Train Acc: 0.7561 | Val Acc: 0.7250 | Train ROC: 0.9714 | Val ROC: 0.8895 | Train AP: 0.9685 | Val AP: 0.8877\n",
      "Epoch [117/200] | Train Loss: 0.4608 | Val Loss: 0.4944 | Train Acc: 0.7522 | Val Acc: 0.7225 | Train ROC: 0.9701 | Val ROC: 0.8852 | Train AP: 0.9660 | Val AP: 0.8719\n",
      "Epoch [118/200] | Train Loss: 0.4549 | Val Loss: 0.5120 | Train Acc: 0.7576 | Val Acc: 0.7475 | Train ROC: 0.9693 | Val ROC: 0.8936 | Train AP: 0.9648 | Val AP: 0.8790\n",
      "Epoch [119/200] | Train Loss: 0.4595 | Val Loss: 0.5472 | Train Acc: 0.7579 | Val Acc: 0.6800 | Train ROC: 0.9699 | Val ROC: 0.9166 | Train AP: 0.9650 | Val AP: 0.9197\n",
      "Epoch [120/200] | Train Loss: 0.4565 | Val Loss: 0.4909 | Train Acc: 0.7516 | Val Acc: 0.7175 | Train ROC: 0.9683 | Val ROC: 0.8969 | Train AP: 0.9624 | Val AP: 0.8926\n",
      "Epoch [121/200] | Train Loss: 0.4543 | Val Loss: 0.5042 | Train Acc: 0.7588 | Val Acc: 0.7600 | Train ROC: 0.9721 | Val ROC: 0.9228 | Train AP: 0.9685 | Val AP: 0.9258\n",
      "Epoch [122/200] | Train Loss: 0.4591 | Val Loss: 0.5043 | Train Acc: 0.7589 | Val Acc: 0.7475 | Train ROC: 0.9743 | Val ROC: 0.9188 | Train AP: 0.9706 | Val AP: 0.9101\n",
      "Epoch [123/200] | Train Loss: 0.4566 | Val Loss: 0.4825 | Train Acc: 0.7521 | Val Acc: 0.7275 | Train ROC: 0.9730 | Val ROC: 0.9058 | Train AP: 0.9705 | Val AP: 0.9119\n",
      "Epoch [124/200] | Train Loss: 0.4514 | Val Loss: 0.4694 | Train Acc: 0.7516 | Val Acc: 0.7250 | Train ROC: 0.9723 | Val ROC: 0.9213 | Train AP: 0.9679 | Val AP: 0.9283\n",
      "Epoch [125/200] | Train Loss: 0.4462 | Val Loss: 0.4883 | Train Acc: 0.7531 | Val Acc: 0.7275 | Train ROC: 0.9728 | Val ROC: 0.8922 | Train AP: 0.9686 | Val AP: 0.8760\n",
      "Epoch [126/200] | Train Loss: 0.4593 | Val Loss: 0.4943 | Train Acc: 0.7588 | Val Acc: 0.7225 | Train ROC: 0.9727 | Val ROC: 0.8861 | Train AP: 0.9689 | Val AP: 0.8740\n",
      "Epoch [127/200] | Train Loss: 0.4543 | Val Loss: 0.4926 | Train Acc: 0.7551 | Val Acc: 0.7600 | Train ROC: 0.9745 | Val ROC: 0.9039 | Train AP: 0.9699 | Val AP: 0.9060\n",
      "Epoch [128/200] | Train Loss: 0.4540 | Val Loss: 0.5151 | Train Acc: 0.7484 | Val Acc: 0.7625 | Train ROC: 0.9723 | Val ROC: 0.9336 | Train AP: 0.9692 | Val AP: 0.9352\n",
      "Epoch [129/200] | Train Loss: 0.4581 | Val Loss: 0.5339 | Train Acc: 0.7562 | Val Acc: 0.7150 | Train ROC: 0.9748 | Val ROC: 0.8866 | Train AP: 0.9716 | Val AP: 0.8854\n",
      "Epoch [130/200] | Train Loss: 0.4544 | Val Loss: 0.4871 | Train Acc: 0.7581 | Val Acc: 0.7600 | Train ROC: 0.9775 | Val ROC: 0.9222 | Train AP: 0.9738 | Val AP: 0.9194\n",
      "Epoch [131/200] | Train Loss: 0.4485 | Val Loss: 0.4714 | Train Acc: 0.7519 | Val Acc: 0.7300 | Train ROC: 0.9738 | Val ROC: 0.9181 | Train AP: 0.9695 | Val AP: 0.9192\n",
      "Epoch [132/200] | Train Loss: 0.4514 | Val Loss: 0.5006 | Train Acc: 0.7572 | Val Acc: 0.7200 | Train ROC: 0.9767 | Val ROC: 0.9143 | Train AP: 0.9710 | Val AP: 0.9216\n",
      "Epoch [133/200] | Train Loss: 0.4564 | Val Loss: 0.5161 | Train Acc: 0.7585 | Val Acc: 0.7625 | Train ROC: 0.9756 | Val ROC: 0.9310 | Train AP: 0.9705 | Val AP: 0.9308\n",
      "Epoch [134/200] | Train Loss: 0.4479 | Val Loss: 0.4855 | Train Acc: 0.7566 | Val Acc: 0.7550 | Train ROC: 0.9743 | Val ROC: 0.9275 | Train AP: 0.9673 | Val AP: 0.9299\n",
      "Epoch [135/200] | Train Loss: 0.4468 | Val Loss: 0.5277 | Train Acc: 0.7642 | Val Acc: 0.7750 | Train ROC: 0.9765 | Val ROC: 0.9320 | Train AP: 0.9737 | Val AP: 0.9285\n",
      "Epoch [136/200] | Train Loss: 0.4465 | Val Loss: 0.5080 | Train Acc: 0.7555 | Val Acc: 0.7425 | Train ROC: 0.9764 | Val ROC: 0.9183 | Train AP: 0.9716 | Val AP: 0.9244\n",
      "Epoch [137/200] | Train Loss: 0.4523 | Val Loss: 0.5660 | Train Acc: 0.7548 | Val Acc: 0.7225 | Train ROC: 0.9794 | Val ROC: 0.9178 | Train AP: 0.9763 | Val AP: 0.9220\n",
      "Epoch [138/200] | Train Loss: 0.4498 | Val Loss: 0.5111 | Train Acc: 0.7491 | Val Acc: 0.7275 | Train ROC: 0.9785 | Val ROC: 0.8896 | Train AP: 0.9739 | Val AP: 0.8940\n",
      "Epoch [139/200] | Train Loss: 0.4418 | Val Loss: 0.4848 | Train Acc: 0.7581 | Val Acc: 0.7450 | Train ROC: 0.9775 | Val ROC: 0.9254 | Train AP: 0.9730 | Val AP: 0.9263\n",
      "Epoch [140/200] | Train Loss: 0.4513 | Val Loss: 0.4836 | Train Acc: 0.7482 | Val Acc: 0.7225 | Train ROC: 0.9752 | Val ROC: 0.9052 | Train AP: 0.9693 | Val AP: 0.9092\n",
      "Epoch [141/200] | Train Loss: 0.4508 | Val Loss: 0.4889 | Train Acc: 0.7539 | Val Acc: 0.7725 | Train ROC: 0.9785 | Val ROC: 0.9391 | Train AP: 0.9746 | Val AP: 0.9358\n",
      "Epoch [142/200] | Train Loss: 0.4359 | Val Loss: 0.5011 | Train Acc: 0.7555 | Val Acc: 0.7550 | Train ROC: 0.9784 | Val ROC: 0.9294 | Train AP: 0.9746 | Val AP: 0.9365\n",
      "Epoch [143/200] | Train Loss: 0.4491 | Val Loss: 0.4678 | Train Acc: 0.7609 | Val Acc: 0.7125 | Train ROC: 0.9792 | Val ROC: 0.9223 | Train AP: 0.9763 | Val AP: 0.9279\n",
      "Epoch [144/200] | Train Loss: 0.4464 | Val Loss: 0.4716 | Train Acc: 0.7574 | Val Acc: 0.7525 | Train ROC: 0.9790 | Val ROC: 0.9279 | Train AP: 0.9749 | Val AP: 0.9145\n",
      "Epoch [145/200] | Train Loss: 0.4461 | Val Loss: 0.5004 | Train Acc: 0.7599 | Val Acc: 0.7550 | Train ROC: 0.9816 | Val ROC: 0.9250 | Train AP: 0.9774 | Val AP: 0.9202\n",
      "Epoch [146/200] | Train Loss: 0.4415 | Val Loss: 0.4998 | Train Acc: 0.7541 | Val Acc: 0.7225 | Train ROC: 0.9792 | Val ROC: 0.9045 | Train AP: 0.9757 | Val AP: 0.9140\n",
      "Epoch [147/200] | Train Loss: 0.4427 | Val Loss: 0.5006 | Train Acc: 0.7546 | Val Acc: 0.7650 | Train ROC: 0.9809 | Val ROC: 0.9224 | Train AP: 0.9770 | Val AP: 0.9227\n",
      "Epoch [148/200] | Train Loss: 0.4449 | Val Loss: 0.4848 | Train Acc: 0.7538 | Val Acc: 0.7400 | Train ROC: 0.9801 | Val ROC: 0.9229 | Train AP: 0.9760 | Val AP: 0.9243\n",
      "Epoch [149/200] | Train Loss: 0.4504 | Val Loss: 0.5192 | Train Acc: 0.7614 | Val Acc: 0.7225 | Train ROC: 0.9781 | Val ROC: 0.9117 | Train AP: 0.9725 | Val AP: 0.9043\n",
      "Epoch [150/200] | Train Loss: 0.4455 | Val Loss: 0.4833 | Train Acc: 0.7500 | Val Acc: 0.7250 | Train ROC: 0.9801 | Val ROC: 0.8926 | Train AP: 0.9772 | Val AP: 0.8991\n",
      "Epoch [151/200] | Train Loss: 0.4434 | Val Loss: 0.5142 | Train Acc: 0.7541 | Val Acc: 0.7375 | Train ROC: 0.9821 | Val ROC: 0.9158 | Train AP: 0.9784 | Val AP: 0.9193\n",
      "Epoch [152/200] | Train Loss: 0.4442 | Val Loss: 0.4749 | Train Acc: 0.7548 | Val Acc: 0.7300 | Train ROC: 0.9819 | Val ROC: 0.9170 | Train AP: 0.9765 | Val AP: 0.9153\n",
      "Epoch [153/200] | Train Loss: 0.4413 | Val Loss: 0.5029 | Train Acc: 0.7478 | Val Acc: 0.7575 | Train ROC: 0.9809 | Val ROC: 0.9338 | Train AP: 0.9765 | Val AP: 0.9381\n",
      "Epoch [154/200] | Train Loss: 0.4415 | Val Loss: 0.5047 | Train Acc: 0.7550 | Val Acc: 0.7375 | Train ROC: 0.9822 | Val ROC: 0.9327 | Train AP: 0.9783 | Val AP: 0.9403\n",
      "Epoch [155/200] | Train Loss: 0.4456 | Val Loss: 0.4861 | Train Acc: 0.7554 | Val Acc: 0.7075 | Train ROC: 0.9830 | Val ROC: 0.9103 | Train AP: 0.9798 | Val AP: 0.9081\n",
      "Epoch [156/200] | Train Loss: 0.4510 | Val Loss: 0.4925 | Train Acc: 0.7555 | Val Acc: 0.7725 | Train ROC: 0.9845 | Val ROC: 0.9263 | Train AP: 0.9807 | Val AP: 0.9179\n",
      "Epoch [157/200] | Train Loss: 0.4406 | Val Loss: 0.4881 | Train Acc: 0.7568 | Val Acc: 0.7225 | Train ROC: 0.9825 | Val ROC: 0.9059 | Train AP: 0.9797 | Val AP: 0.9067\n",
      "Epoch [158/200] | Train Loss: 0.4439 | Val Loss: 0.4853 | Train Acc: 0.7584 | Val Acc: 0.7275 | Train ROC: 0.9860 | Val ROC: 0.9247 | Train AP: 0.9840 | Val AP: 0.9345\n",
      "Epoch [159/200] | Train Loss: 0.4417 | Val Loss: 0.5248 | Train Acc: 0.7515 | Val Acc: 0.7400 | Train ROC: 0.9851 | Val ROC: 0.9274 | Train AP: 0.9822 | Val AP: 0.9336\n",
      "Epoch [160/200] | Train Loss: 0.4411 | Val Loss: 0.4947 | Train Acc: 0.7552 | Val Acc: 0.7675 | Train ROC: 0.9857 | Val ROC: 0.9309 | Train AP: 0.9826 | Val AP: 0.9380\n",
      "Epoch [161/200] | Train Loss: 0.4427 | Val Loss: 0.4561 | Train Acc: 0.7480 | Val Acc: 0.7425 | Train ROC: 0.9846 | Val ROC: 0.9169 | Train AP: 0.9809 | Val AP: 0.9153\n",
      "Epoch [162/200] | Train Loss: 0.4335 | Val Loss: 0.5310 | Train Acc: 0.7541 | Val Acc: 0.7275 | Train ROC: 0.9834 | Val ROC: 0.9113 | Train AP: 0.9777 | Val AP: 0.9147\n",
      "Epoch [163/200] | Train Loss: 0.4339 | Val Loss: 0.4691 | Train Acc: 0.7494 | Val Acc: 0.7175 | Train ROC: 0.9848 | Val ROC: 0.9047 | Train AP: 0.9819 | Val AP: 0.9028\n",
      "Epoch [164/200] | Train Loss: 0.4463 | Val Loss: 0.4806 | Train Acc: 0.7494 | Val Acc: 0.7300 | Train ROC: 0.9830 | Val ROC: 0.9002 | Train AP: 0.9797 | Val AP: 0.8836\n",
      "Epoch [165/200] | Train Loss: 0.4415 | Val Loss: 0.5118 | Train Acc: 0.7566 | Val Acc: 0.7450 | Train ROC: 0.9843 | Val ROC: 0.9322 | Train AP: 0.9804 | Val AP: 0.9406\n",
      "Epoch [166/200] | Train Loss: 0.4361 | Val Loss: 0.4874 | Train Acc: 0.7556 | Val Acc: 0.7425 | Train ROC: 0.9868 | Val ROC: 0.9116 | Train AP: 0.9852 | Val AP: 0.9062\n",
      "Epoch [167/200] | Train Loss: 0.4322 | Val Loss: 0.4787 | Train Acc: 0.7556 | Val Acc: 0.7250 | Train ROC: 0.9842 | Val ROC: 0.9247 | Train AP: 0.9806 | Val AP: 0.9317\n",
      "Epoch [168/200] | Train Loss: 0.4343 | Val Loss: 0.4684 | Train Acc: 0.7514 | Val Acc: 0.7625 | Train ROC: 0.9866 | Val ROC: 0.9262 | Train AP: 0.9839 | Val AP: 0.9272\n",
      "Epoch [169/200] | Train Loss: 0.4400 | Val Loss: 0.4637 | Train Acc: 0.7566 | Val Acc: 0.7300 | Train ROC: 0.9882 | Val ROC: 0.9195 | Train AP: 0.9858 | Val AP: 0.9233\n",
      "Epoch [170/200] | Train Loss: 0.4514 | Val Loss: 0.5136 | Train Acc: 0.7516 | Val Acc: 0.7450 | Train ROC: 0.9866 | Val ROC: 0.9304 | Train AP: 0.9829 | Val AP: 0.9366\n",
      "Epoch [171/200] | Train Loss: 0.4343 | Val Loss: 0.5362 | Train Acc: 0.7524 | Val Acc: 0.7250 | Train ROC: 0.9868 | Val ROC: 0.9178 | Train AP: 0.9845 | Val AP: 0.9249\n",
      "Epoch [172/200] | Train Loss: 0.4330 | Val Loss: 0.5098 | Train Acc: 0.7514 | Val Acc: 0.7125 | Train ROC: 0.9878 | Val ROC: 0.9179 | Train AP: 0.9856 | Val AP: 0.9222\n",
      "Epoch [173/200] | Train Loss: 0.4381 | Val Loss: 0.4743 | Train Acc: 0.7578 | Val Acc: 0.7400 | Train ROC: 0.9870 | Val ROC: 0.9314 | Train AP: 0.9844 | Val AP: 0.9395\n",
      "Epoch [174/200] | Train Loss: 0.4341 | Val Loss: 0.4957 | Train Acc: 0.7608 | Val Acc: 0.7200 | Train ROC: 0.9862 | Val ROC: 0.9234 | Train AP: 0.9827 | Val AP: 0.9341\n",
      "Epoch [175/200] | Train Loss: 0.4375 | Val Loss: 0.4983 | Train Acc: 0.7616 | Val Acc: 0.7250 | Train ROC: 0.9867 | Val ROC: 0.9147 | Train AP: 0.9830 | Val AP: 0.9265\n",
      "Epoch [176/200] | Train Loss: 0.4302 | Val Loss: 0.4649 | Train Acc: 0.7591 | Val Acc: 0.7075 | Train ROC: 0.9881 | Val ROC: 0.9180 | Train AP: 0.9856 | Val AP: 0.9255\n",
      "Epoch [177/200] | Train Loss: 0.4371 | Val Loss: 0.4953 | Train Acc: 0.7612 | Val Acc: 0.7600 | Train ROC: 0.9895 | Val ROC: 0.9259 | Train AP: 0.9876 | Val AP: 0.9126\n",
      "Epoch [178/200] | Train Loss: 0.4407 | Val Loss: 0.5077 | Train Acc: 0.7574 | Val Acc: 0.7625 | Train ROC: 0.9888 | Val ROC: 0.9192 | Train AP: 0.9873 | Val AP: 0.9239\n",
      "Epoch [179/200] | Train Loss: 0.4377 | Val Loss: 0.4923 | Train Acc: 0.7574 | Val Acc: 0.7375 | Train ROC: 0.9890 | Val ROC: 0.9331 | Train AP: 0.9857 | Val AP: 0.9400\n",
      "Epoch [180/200] | Train Loss: 0.4375 | Val Loss: 0.5417 | Train Acc: 0.7572 | Val Acc: 0.7075 | Train ROC: 0.9864 | Val ROC: 0.9202 | Train AP: 0.9837 | Val AP: 0.9317\n",
      "Epoch [181/200] | Train Loss: 0.4344 | Val Loss: 0.5317 | Train Acc: 0.7595 | Val Acc: 0.7550 | Train ROC: 0.9895 | Val ROC: 0.9367 | Train AP: 0.9876 | Val AP: 0.9430\n",
      "Epoch [182/200] | Train Loss: 0.4320 | Val Loss: 0.5025 | Train Acc: 0.7564 | Val Acc: 0.7275 | Train ROC: 0.9869 | Val ROC: 0.9248 | Train AP: 0.9830 | Val AP: 0.9284\n",
      "Epoch [183/200] | Train Loss: 0.4361 | Val Loss: 0.4738 | Train Acc: 0.7545 | Val Acc: 0.7300 | Train ROC: 0.9892 | Val ROC: 0.9133 | Train AP: 0.9866 | Val AP: 0.9149\n",
      "Epoch [184/200] | Train Loss: 0.4279 | Val Loss: 0.4816 | Train Acc: 0.7556 | Val Acc: 0.7125 | Train ROC: 0.9880 | Val ROC: 0.9030 | Train AP: 0.9847 | Val AP: 0.9071\n",
      "Epoch [185/200] | Train Loss: 0.4267 | Val Loss: 0.4751 | Train Acc: 0.7572 | Val Acc: 0.7625 | Train ROC: 0.9895 | Val ROC: 0.9400 | Train AP: 0.9870 | Val AP: 0.9510\n",
      "Epoch [186/200] | Train Loss: 0.4310 | Val Loss: 0.4730 | Train Acc: 0.7596 | Val Acc: 0.7500 | Train ROC: 0.9882 | Val ROC: 0.9230 | Train AP: 0.9853 | Val AP: 0.9265\n",
      "Epoch [187/200] | Train Loss: 0.4388 | Val Loss: 0.5071 | Train Acc: 0.7544 | Val Acc: 0.7725 | Train ROC: 0.9882 | Val ROC: 0.9305 | Train AP: 0.9850 | Val AP: 0.9209\n",
      "Epoch [188/200] | Train Loss: 0.4263 | Val Loss: 0.4868 | Train Acc: 0.7551 | Val Acc: 0.7175 | Train ROC: 0.9897 | Val ROC: 0.9149 | Train AP: 0.9858 | Val AP: 0.9232\n",
      "Epoch [189/200] | Train Loss: 0.4324 | Val Loss: 0.4786 | Train Acc: 0.7556 | Val Acc: 0.7350 | Train ROC: 0.9868 | Val ROC: 0.9313 | Train AP: 0.9817 | Val AP: 0.9347\n",
      "Epoch [190/200] | Train Loss: 0.4284 | Val Loss: 0.4687 | Train Acc: 0.7554 | Val Acc: 0.7125 | Train ROC: 0.9889 | Val ROC: 0.9312 | Train AP: 0.9863 | Val AP: 0.9399\n",
      "Epoch [191/200] | Train Loss: 0.4306 | Val Loss: 0.4558 | Train Acc: 0.7634 | Val Acc: 0.7475 | Train ROC: 0.9900 | Val ROC: 0.9418 | Train AP: 0.9879 | Val AP: 0.9478\n",
      "Epoch [192/200] | Train Loss: 0.4208 | Val Loss: 0.4729 | Train Acc: 0.7659 | Val Acc: 0.7600 | Train ROC: 0.9896 | Val ROC: 0.9197 | Train AP: 0.9863 | Val AP: 0.9188\n",
      "Epoch [193/200] | Train Loss: 0.4309 | Val Loss: 0.4807 | Train Acc: 0.7529 | Val Acc: 0.7425 | Train ROC: 0.9894 | Val ROC: 0.9233 | Train AP: 0.9866 | Val AP: 0.9330\n",
      "Epoch [194/200] | Train Loss: 0.4395 | Val Loss: 0.4968 | Train Acc: 0.7580 | Val Acc: 0.7500 | Train ROC: 0.9903 | Val ROC: 0.9334 | Train AP: 0.9881 | Val AP: 0.9395\n",
      "Epoch [195/200] | Train Loss: 0.4248 | Val Loss: 0.4664 | Train Acc: 0.7530 | Val Acc: 0.7425 | Train ROC: 0.9901 | Val ROC: 0.9175 | Train AP: 0.9878 | Val AP: 0.9232\n",
      "Epoch [196/200] | Train Loss: 0.4302 | Val Loss: 0.4663 | Train Acc: 0.7549 | Val Acc: 0.7275 | Train ROC: 0.9896 | Val ROC: 0.9065 | Train AP: 0.9866 | Val AP: 0.9126\n",
      "Epoch [197/200] | Train Loss: 0.4289 | Val Loss: 0.4911 | Train Acc: 0.7570 | Val Acc: 0.7775 | Train ROC: 0.9908 | Val ROC: 0.9392 | Train AP: 0.9891 | Val AP: 0.9462\n",
      "Epoch [198/200] | Train Loss: 0.4293 | Val Loss: 0.4724 | Train Acc: 0.7576 | Val Acc: 0.7500 | Train ROC: 0.9918 | Val ROC: 0.9291 | Train AP: 0.9903 | Val AP: 0.9293\n",
      "Epoch [199/200] | Train Loss: 0.4332 | Val Loss: 0.4657 | Train Acc: 0.7484 | Val Acc: 0.7250 | Train ROC: 0.9901 | Val ROC: 0.9165 | Train AP: 0.9881 | Val AP: 0.9238\n",
      "Epoch [200/200] | Train Loss: 0.4288 | Val Loss: 0.4647 | Train Acc: 0.7566 | Val Acc: 0.7325 | Train ROC: 0.9891 | Val ROC: 0.9223 | Train AP: 0.9853 | Val AP: 0.9237\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # ---------- TRAIN ----------\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass on training adjacency\n",
    "    adj_recon = model(x, pos_enc, train_adj)\n",
    "\n",
    "    # Compute sampled loss (balanced positives/negatives)\n",
    "    total_loss, recon_loss, kl_loss = sampled_vae_loss(\n",
    "        adj_recon, train_adj, model.z_mean, model.z_logvar, num_samples=8000\n",
    "    )\n",
    "\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Metrics (sampled)\n",
    "    roc_train, ap_train, acc_train = sampled_metrics(adj_recon, train_adj, num_samples=8000)\n",
    "\n",
    "    # ---------- VALIDATION ----------\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        adj_val_recon = model(x, pos_enc, val_adj)\n",
    "        val_loss, _, _ = sampled_vae_loss(\n",
    "            adj_val_recon, val_adj, model.z_mean, model.z_logvar, num_samples=400\n",
    "        )\n",
    "        roc_val, ap_val, acc_val = sampled_metrics(adj_val_recon, val_adj, num_samples=400)\n",
    "\n",
    "    # ---------- LOGGING ----------\n",
    "    print(\n",
    "        f\"Epoch [{epoch:03d}/{num_epochs}] | \"\n",
    "        f\"Train Loss: {total_loss.item():.4f} | Val Loss: {val_loss.item():.4f} | \"\n",
    "        f\"Train Acc: {acc_train:.4f} | Val Acc: {acc_val:.4f} | \"\n",
    "        f\"Train ROC: {roc_train:.4f} | Val ROC: {roc_val:.4f} | \"\n",
    "        f\"Train AP: {ap_train:.4f} | Val AP: {ap_val:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9630f7b8-bcc7-4942-8e45-c9863a4edd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)\n",
    "def test_model(model, x, pos_e, test_adj, num_samples):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        adj_test_recon = model(x, pos_enc, test_adj)\n",
    "    \n",
    "        # Balanced sampled VAE loss\n",
    "        test_loss, _, _ = sampled_vae_loss(\n",
    "            adj_test_recon, test_adj, model.z_mean, model.z_logvar, num_samples=1054\n",
    "\n",
    "        )\n",
    "    \n",
    "        # Sampled metrics (balanced)\n",
    "        roc_test, ap_test, acc_test = sampled_metrics(\n",
    "            adj_test_recon, test_adj, num_samples=num_samples\n",
    "        )\n",
    "    return test_loss, acc_test, roc_test, ap_test\n",
    "\n",
    "exps = 20\n",
    "losses = []\n",
    "accs = []\n",
    "rocs = []\n",
    "precs = []\n",
    "for i in range(exps):\n",
    "    torch.manual_seed(42 + i)\n",
    "    t_loss, t_acc, t_roc, t_prec = test_model(model, x, pos_enc, test_adj, num_samples=1000)\n",
    "    losses.append(t_loss.detach().cpu().item())\n",
    "    accs.append(t_acc)\n",
    "    rocs.append(t_roc)\n",
    "    precs.append(t_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbd3453b-4cb2-4640-91a4-6356b0a2c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.array(losses)\n",
    "accs = np.array(accs)\n",
    "rocs = np.array(rocs)\n",
    "precs = np.array(precs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf805990-23a5-473a-bf54-7bdeb6b91e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL TEST RESULTS ===\n",
      "Test Loss: 0.4981 +- 0.011562777382434627 | \n",
      "Test Acc: 0.7343 +- 0.01081711606667878 | \n",
      "ROC-AUC: 0.9161 +- 0.005897844162064628 |\n",
      "AP: 0.9235 +- 0.00753070491905668\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== FINAL TEST RESULTS ===\")\n",
    "print(\n",
    "    f\"Test Loss: {losses.mean():.4f} +- {losses.std()} | \\n\"\n",
    "    f\"Test Acc: {accs.mean():.4f} +- {accs.std()} | \\n\"\n",
    "    f\"ROC-AUC: {rocs.mean():.4f} +- {rocs.std()} |\\nAP: {precs.mean():.4f} +- {precs.std()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb76eaf-039e-4a37-ac09-4c0c4bcce5d1",
   "metadata": {},
   "source": [
    "=== FINAL TEST RESULTS ===\n",
    "kl: 0.005\n",
    "n_heads = 4\n",
    "dim = 128\n",
    "n_layers = 4\n",
    "\n",
    "Test Loss: 0.4868 +- 0.009812361955942385 | \n",
    "Test Acc: 0.7414 +- 0.008182145195485114 | \n",
    "ROC-AUC: 0.9176 +- 0.005479434469906512 |\n",
    "AP: 0.9240 +- 0.007316556545360688"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaced33-c391-4aaf-b455-1bd0f5a6181a",
   "metadata": {},
   "source": [
    "kl: 0.0005\n",
    "lr: 0.0001\n",
    "\n",
    "=== FINAL TEST RESULTS ===\n",
    "Test Loss: 0.5380 +- 0.014766905705631252 | \n",
    "Test Acc: 0.7196 +- 0.008816320094007483 | \n",
    "ROC-AUC: 0.8679 +- 0.007809779471278348 |\n",
    "AP: 0.8753 +- 0.009753158063202054"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052ca9e4-611e-4d75-8083-cc9aa089c0ba",
   "metadata": {},
   "source": [
    "# Best Result\n",
    "\n",
    "kl: 0.0005\n",
    "lr: 1e-3\n",
    "n_heads = 4, n_layers=4, pos_dim=128, hidden_dim=128\n",
    "\n",
    "=== FINAL TEST RESULTS ===\n",
    "Test Loss: 0.4818 +- 0.007868968959063699 | \n",
    "Test Acc: 0.7419 +- 0.01077253452071518 | \n",
    "ROC-AUC: 0.9204 +- 0.006907713010830738 |\n",
    "AP: 0.9266 +- 0.008169060892064308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2299fb93-c513-4298-8c92-171d1378c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"92_4H_4L_128.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a51a1a22-668e-413c-acce-a5f8cc073676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:335: RuntimeWarning: divide by zero encountered in matmul\n",
      "  Q, _ = normalizer(A @ Q)\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:335: RuntimeWarning: overflow encountered in matmul\n",
      "  Q, _ = normalizer(A @ Q)\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:335: RuntimeWarning: invalid value encountered in matmul\n",
      "  Q, _ = normalizer(A @ Q)\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  Q, _ = normalizer(A.T @ Q)\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  Q, _ = normalizer(A.T @ Q)\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  Q, _ = normalizer(A.T @ Q)\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:340: RuntimeWarning: divide by zero encountered in matmul\n",
      "  Q, _ = qr_normalizer(A @ Q)\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:340: RuntimeWarning: overflow encountered in matmul\n",
      "  Q, _ = qr_normalizer(A @ Q)\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:340: RuntimeWarning: invalid value encountered in matmul\n",
      "  Q, _ = qr_normalizer(A @ Q)\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:533: RuntimeWarning: divide by zero encountered in matmul\n",
      "  B = Q.T @ M\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:533: RuntimeWarning: overflow encountered in matmul\n",
      "  B = Q.T @ M\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:533: RuntimeWarning: invalid value encountered in matmul\n",
      "  B = Q.T @ M\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:547: RuntimeWarning: divide by zero encountered in matmul\n",
      "  U = Q @ Uhat\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:547: RuntimeWarning: overflow encountered in matmul\n",
      "  U = Q @ Uhat\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:547: RuntimeWarning: invalid value encountered in matmul\n",
      "  U = Q @ Uhat\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:335: RuntimeWarning: divide by zero encountered in matmul\n",
      "  Q, _ = normalizer(A @ Q)\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:335: RuntimeWarning: overflow encountered in matmul\n",
      "  Q, _ = normalizer(A @ Q)\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:335: RuntimeWarning: invalid value encountered in matmul\n",
      "  Q, _ = normalizer(A @ Q)\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  Q, _ = normalizer(A.T @ Q)\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  Q, _ = normalizer(A.T @ Q)\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  Q, _ = normalizer(A.T @ Q)\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:340: RuntimeWarning: divide by zero encountered in matmul\n",
      "  Q, _ = qr_normalizer(A @ Q)\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:340: RuntimeWarning: overflow encountered in matmul\n",
      "  Q, _ = qr_normalizer(A @ Q)\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:340: RuntimeWarning: invalid value encountered in matmul\n",
      "  Q, _ = qr_normalizer(A @ Q)\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:533: RuntimeWarning: divide by zero encountered in matmul\n",
      "  B = Q.T @ M\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:533: RuntimeWarning: overflow encountered in matmul\n",
      "  B = Q.T @ M\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:533: RuntimeWarning: invalid value encountered in matmul\n",
      "  B = Q.T @ M\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:547: RuntimeWarning: divide by zero encountered in matmul\n",
      "  U = Q @ Uhat\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:547: RuntimeWarning: overflow encountered in matmul\n",
      "  U = Q @ Uhat\n",
      "/Users/sid/COLLEGE_MATERIALS/Research/research/lib/python3.9/site-packages/sklearn/utils/extmath.py:547: RuntimeWarning: invalid value encountered in matmul\n",
      "  U = Q @ Uhat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'latent_2d': '/Users/sid/COLLEGE_MATERIALS/Research/vgae_pytorch/visualizations/latent_tsne_2d_20251021_093826.png',\n",
       " 'latent_3d': '/Users/sid/COLLEGE_MATERIALS/Research/vgae_pytorch/visualizations/latent_tsne_3d_20251021_093839.html',\n",
       " 'adj_comparison': '/Users/sid/COLLEGE_MATERIALS/Research/vgae_pytorch/visualizations/adjacency_comparison_20251021_093850.png',\n",
       " 'link_confidence': '/Users/sid/COLLEGE_MATERIALS/Research/vgae_pytorch/visualizations/link_confidence_20251021_093902.png',\n",
       " 'attention_stats': '/Users/sid/COLLEGE_MATERIALS/Research/vgae_pytorch/visualizations/attention_stats_20251021_093906.png',\n",
       " 'attention_layer_files': ['/Users/sid/COLLEGE_MATERIALS/Research/vgae_pytorch/visualizations/attention_layer_0_20251021_093924.png',\n",
       "  '/Users/sid/COLLEGE_MATERIALS/Research/vgae_pytorch/visualizations/attention_layer_1_20251021_093956.png',\n",
       "  '/Users/sid/COLLEGE_MATERIALS/Research/vgae_pytorch/visualizations/attention_layer_2_20251021_094028.png',\n",
       "  '/Users/sid/COLLEGE_MATERIALS/Research/vgae_pytorch/visualizations/attention_layer_3_20251021_094059.png']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from analysis_model import run_full_analysis\n",
    "run_full_analysis(model, x, pos_enc, train_adj, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9c5037-58bb-4104-a935-f5b68bfe7dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
